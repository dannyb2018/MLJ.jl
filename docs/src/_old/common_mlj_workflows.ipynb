{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common MLJ Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ\n",
    "using RDatasets\n",
    "channing = dataset(\"boot\", \"channing\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting metadata, including column scientific types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(names = (:Sex, :Entry, :Exit, :Time, :Cens),\n",
       " types = (CategoricalString{UInt8}, Int32, Int32, Int32, Int32),\n",
       " scitypes = (Multiclass{2}, Count, Count, Count, Count),\n",
       " nrows = 462,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema(channing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpacking data and correcting for wrong scitypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌\u001b[0m──────────────────────────\u001b[0m┬\u001b[0m────────────\u001b[0m┬\u001b[0m───────────────────────────────\u001b[0m┐\u001b[0m\n",
      "│\u001b[0m\u001b[1m Sex                      \u001b[0m│\u001b[0m\u001b[1m Entry      \u001b[0m│\u001b[0m\u001b[1m Cens                          \u001b[0m│\u001b[0m\n",
      "│\u001b[0m\u001b[90m CategoricalString{UInt8} \u001b[0m│\u001b[0m\u001b[90m Float64    \u001b[0m│\u001b[0m\u001b[90m CategoricalValue{Int32,UInt8} \u001b[0m│\u001b[0m\n",
      "│\u001b[0m\u001b[90m Multiclass{2}            \u001b[0m│\u001b[0m\u001b[90m Continuous \u001b[0m│\u001b[0m\u001b[90m Multiclass{2}                 \u001b[0m│\u001b[0m\n",
      "├\u001b[0m──────────────────────────\u001b[0m┼\u001b[0m────────────\u001b[0m┼\u001b[0m───────────────────────────────\u001b[0m┤\u001b[0m\n",
      "│\u001b[0m Male                     \u001b[0m│\u001b[0m 782.0      \u001b[0m│\u001b[0m 1                             \u001b[0m│\u001b[0m\n",
      "│\u001b[0m Male                     \u001b[0m│\u001b[0m 1020.0     \u001b[0m│\u001b[0m 1                             \u001b[0m│\u001b[0m\n",
      "│\u001b[0m Male                     \u001b[0m│\u001b[0m 856.0      \u001b[0m│\u001b[0m 1                             \u001b[0m│\u001b[0m\n",
      "│\u001b[0m Male                     \u001b[0m│\u001b[0m 915.0      \u001b[0m│\u001b[0m 1                             \u001b[0m│\u001b[0m\n",
      "└\u001b[0m──────────────────────────\u001b[0m┴\u001b[0m────────────\u001b[0m┴\u001b[0m───────────────────────────────\u001b[0m┘\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "y, X =  unpack(channing,\n",
    "               ==(:Exit),            # y is the :Exit column\n",
    "               !=(:Time);            # X is the rest, except :Time\n",
    "               :Exit=>Continuous,\n",
    "               :Entry=>Continuous,\n",
    "               :Cens=>Multiclass)\n",
    "first(X, 4) |> pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       "  909.0\n",
       " 1128.0\n",
       "  969.0\n",
       "  957.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a built-in supervised dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌\u001b[0m──────────────\u001b[0m┬\u001b[0m─────────────\u001b[0m┬\u001b[0m──────────────\u001b[0m┬\u001b[0m─────────────\u001b[0m┐\u001b[0m\n",
      "│\u001b[0m\u001b[1m sepal_length \u001b[0m│\u001b[0m\u001b[1m sepal_width \u001b[0m│\u001b[0m\u001b[1m petal_length \u001b[0m│\u001b[0m\u001b[1m petal_width \u001b[0m│\u001b[0m\n",
      "│\u001b[0m\u001b[90m Float64      \u001b[0m│\u001b[0m\u001b[90m Float64     \u001b[0m│\u001b[0m\u001b[90m Float64      \u001b[0m│\u001b[0m\u001b[90m Float64     \u001b[0m│\u001b[0m\n",
      "│\u001b[0m\u001b[90m Continuous   \u001b[0m│\u001b[0m\u001b[90m Continuous  \u001b[0m│\u001b[0m\u001b[90m Continuous   \u001b[0m│\u001b[0m\u001b[90m Continuous  \u001b[0m│\u001b[0m\n",
      "├\u001b[0m──────────────\u001b[0m┼\u001b[0m─────────────\u001b[0m┼\u001b[0m──────────────\u001b[0m┼\u001b[0m─────────────\u001b[0m┤\u001b[0m\n",
      "│\u001b[0m 5.1          \u001b[0m│\u001b[0m 3.5         \u001b[0m│\u001b[0m 1.4          \u001b[0m│\u001b[0m 0.2         \u001b[0m│\u001b[0m\n",
      "│\u001b[0m 4.9          \u001b[0m│\u001b[0m 3.0         \u001b[0m│\u001b[0m 1.4          \u001b[0m│\u001b[0m 0.2         \u001b[0m│\u001b[0m\n",
      "│\u001b[0m 4.7          \u001b[0m│\u001b[0m 3.2         \u001b[0m│\u001b[0m 1.3          \u001b[0m│\u001b[0m 0.2         \u001b[0m│\u001b[0m\n",
      "│\u001b[0m 4.6          \u001b[0m│\u001b[0m 3.1         \u001b[0m│\u001b[0m 1.5          \u001b[0m│\u001b[0m 0.2         \u001b[0m│\u001b[0m\n",
      "└\u001b[0m──────────────\u001b[0m┴\u001b[0m─────────────\u001b[0m┴\u001b[0m──────────────\u001b[0m┴\u001b[0m─────────────\u001b[0m┘\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "X, y = @load_iris;\n",
    "first(X, 4) |> pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element CategoricalArray{String,1,UInt32}:\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for a supervised model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37-element Array{NamedTuple,1}:\n",
       " (name = ARDRegressor, package_name = ScikitLearn, ... )                      \n",
       " (name = AdaBoostRegressor, package_name = ScikitLearn, ... )                 \n",
       " (name = BaggingRegressor, package_name = ScikitLearn, ... )                  \n",
       " (name = BayesianRidgeRegressor, package_name = ScikitLearn, ... )            \n",
       " (name = ConstantRegressor, package_name = MLJModels, ... )                   \n",
       " (name = DecisionTreeRegressor, package_name = DecisionTree, ... )            \n",
       " (name = DeterministicConstantRegressor, package_name = MLJModels, ... )      \n",
       " (name = ElasticNetCVRegressor, package_name = ScikitLearn, ... )             \n",
       " (name = ElasticNetRegressor, package_name = ScikitLearn, ... )               \n",
       " (name = EpsilonSVR, package_name = LIBSVM, ... )                             \n",
       " (name = GaussianProcessRegressor, package_name = ScikitLearn, ... )          \n",
       " (name = GradientBoostingRegressor, package_name = ScikitLearn, ... )         \n",
       " (name = HuberRegressor, package_name = ScikitLearn, ... )                    \n",
       " ⋮                                                                            \n",
       " (name = OrthogonalMatchingPursuitRegressor, package_name = ScikitLearn, ... )\n",
       " (name = PassiveAggressiveRegressor, package_name = ScikitLearn, ... )        \n",
       " (name = RandomForestRegressor, package_name = ScikitLearn, ... )             \n",
       " (name = RidgeCVRegressor, package_name = ScikitLearn, ... )                  \n",
       " (name = RidgeRegressor, package_name = MultivariateStats, ... )              \n",
       " (name = RidgeRegressor, package_name = ScikitLearn, ... )                    \n",
       " (name = SGDRegressor, package_name = ScikitLearn, ... )                      \n",
       " (name = SVMLRegressor, package_name = ScikitLearn, ... )                     \n",
       " (name = SVMNuRegressor, package_name = ScikitLearn, ... )                    \n",
       " (name = SVMRegressor, package_name = ScikitLearn, ... )                      \n",
       " (name = TheilSenRegressor, package_name = ScikitLearn, ... )                 \n",
       " (name = XGBoostRegressor, package_name = XGBoost, ... )                      "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = @load_boston\n",
    "models(matching(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[35mDecisionTreeRegressor from DecisionTree.jl.\u001b[39m\n",
       "\u001b[35m[Documentation](https://github.com/bensadeghi/DecisionTree.jl).\u001b[39m\n",
       "(name = \"DecisionTreeRegressor\",\n",
       " package_name = \"DecisionTree\",\n",
       " is_supervised = true,\n",
       " docstring = \"DecisionTreeRegressor from DecisionTree.jl.\\n[Documentation](https://github.com/bensadeghi/DecisionTree.jl).\",\n",
       " hyperparameter_types = [\"Float64\", \"Int64\", \"Int64\", \"Int64\", \"Float64\", \"Int64\", \"Bool\"],\n",
       " hyperparameters = Symbol[:pruning_purity_threshold, :max_depth, :min_samples_leaf, :min_samples_split, :min_purity_increase, :n_subfeatures, :post_prune],\n",
       " implemented_methods = Symbol[:fit, :predict, :clean!, :fitted_params],\n",
       " is_pure_julia = true,\n",
       " is_wrapper = false,\n",
       " load_path = \"MLJModels.DecisionTree_.DecisionTreeRegressor\",\n",
       " package_license = \"unknown\",\n",
       " package_url = \"https://github.com/bensadeghi/DecisionTree.jl\",\n",
       " package_uuid = \"7806a523-6efd-50cb-b5f6-3fa6f1930dbb\",\n",
       " prediction_type = :deterministic,\n",
       " supports_weights = false,\n",
       " input_scitype = ScientificTypes.Table{_s13} where _s13<:(AbstractArray{_s12,1} where _s12<:Continuous),\n",
       " target_scitype = AbstractArray{_s491,1} where _s491<:Continuous,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models(matching(X, y))[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More refined searches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{NamedTuple,1}:\n",
       " (name = DecisionTreeRegressor, package_name = DecisionTree, ... )      \n",
       " (name = DeterministicConstantRegressor, package_name = MLJModels, ... )\n",
       " (name = KNNRegressor, package_name = NearestNeighbors, ... )           \n",
       " (name = RidgeRegressor, package_name = MultivariateStats, ... )        "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models() do model\n",
    "    matching(model, X, y) &&\n",
    "        model.prediction_type == :deterministic &&\n",
    "        model.is_pure_julia\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for an unsupervised model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Array{NamedTuple,1}:\n",
       " (name = FeatureSelector, package_name = MLJModels, ... )  \n",
       " (name = ICA, package_name = MultivariateStats, ... )      \n",
       " (name = KMeans, package_name = Clustering, ... )          \n",
       " (name = KMedoids, package_name = Clustering, ... )        \n",
       " (name = KernelPCA, package_name = MultivariateStats, ... )\n",
       " (name = OneClassSVM, package_name = LIBSVM, ... )         \n",
       " (name = OneHotEncoder, package_name = MLJModels, ... )    \n",
       " (name = PCA, package_name = MultivariateStats, ... )      \n",
       " (name = Standardizer, package_name = MLJModels, ... )     "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models(matching(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the metadata entry for a given model type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[35mRidgeRegressor from MultivariateStats.jl.\u001b[39m\n",
       "\u001b[35m[Documentation](https://github.com/JuliaStats/MultivariateStats.jl).\u001b[39m\n",
       "(name = \"RidgeRegressor\",\n",
       " package_name = \"MultivariateStats\",\n",
       " is_supervised = true,\n",
       " docstring = \"RidgeRegressor from MultivariateStats.jl.\\n[Documentation](https://github.com/JuliaStats/MultivariateStats.jl).\",\n",
       " hyperparameter_types = [\"Float64\"],\n",
       " hyperparameters = Symbol[:lambda],\n",
       " implemented_methods = Symbol[:fit, :predict, :clean!, :fitted_params],\n",
       " is_pure_julia = true,\n",
       " is_wrapper = false,\n",
       " load_path = \"MLJModels.MultivariateStats_.RidgeRegressor\",\n",
       " package_license = \"unknown\",\n",
       " package_url = \"https://github.com/JuliaStats/MultivariateStats.jl\",\n",
       " package_uuid = \"6f286f6a-111f-5878-ab1e-185364afe411\",\n",
       " prediction_type = :deterministic,\n",
       " supports_weights = false,\n",
       " input_scitype = ScientificTypes.Table{_s13} where _s13<:(AbstractArray{_s12,1} where _s12<:Continuous),\n",
       " target_scitype = AbstractArray{Continuous,1},)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info(\"PCA\")\n",
    "info(\"RidgeRegressor\", pkg=\"MultivariateStats\") # a model type in multiple packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *More on model matching*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model` is in the list returned by `models(test)` exactly when\n",
    "  `test(model) == true`. (Here `model` is some model type metadata\n",
    "  entry, as returned by `info(...)`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `matching(model, X, y) == true` exactly when `model` is supervised\n",
    "  and admits inputs and targets with the scientific types of `X` and\n",
    "  `y`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `matching(model, X) == true` exaclty when `model` is unsupervised\n",
    "  and admits inputs with the scientific types of `X`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The testing objects `matching(model)`, `matching(X, y)` and `matching(X)`,\n",
    "  which are callable and `Bool`-valued, are just the curried versions of\n",
    "  the above. So, for example, `matching(X, y)(model) =\n",
    "  matching(model, X, y)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading model code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(pruning_purity = 1.0,\n",
       "                       max_depth = -1,\n",
       "                       min_samples_leaf = 1,\n",
       "                       min_samples_split = 2,\n",
       "                       min_purity_increase = 0.0,\n",
       "                       n_subfeatures = 0,\n",
       "                       display_depth = 5,\n",
       "                       post_prune = false,\n",
       "                       merge_purity_threshold = 0.9,\n",
       "                       pdf_smoothing = 0.05,)\u001b[34m @ 7…72\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@load DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(pruning_purity = 1.0,\n",
       "                       max_depth = 4,\n",
       "                       min_samples_leaf = 1,\n",
       "                       min_samples_split = 5,\n",
       "                       min_purity_increase = 0.0,\n",
       "                       n_subfeatures = 0,\n",
       "                       display_depth = 5,\n",
       "                       post_prune = false,\n",
       "                       merge_purity_threshold = 0.9,\n",
       "                       pdf_smoothing = 0.05,)\u001b[34m @ 7…86\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(min_samples_split=5, max_depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: A model type \"DecisionTreeClassifier\" is already loaded. \n",
      "│ No new code loaded. \n",
      "└ @ MLJModels /Users/anthony/Dropbox/Julia7/MLJ/MLJModels/src/loading.jl:41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = @load DecisionTreeClassifier\n",
    "model.min_samples_split = 5\n",
    "model.max_depth = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 5 folds: 100%[=========================] Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌\u001b[0m─────────\u001b[0m┬\u001b[0m───────────────────\u001b[0m┐\u001b[0m\n",
      "│\u001b[0m\u001b[1m measure \u001b[0m│\u001b[0m\u001b[1m measurement       \u001b[0m│\u001b[0m\n",
      "├\u001b[0m─────────\u001b[0m┼\u001b[0m───────────────────\u001b[0m┤\u001b[0m\n",
      "│\u001b[0m rms     \u001b[0m│\u001b[0m 8.668102471357711 \u001b[0m│\u001b[0m\n",
      "│\u001b[0m mav     \u001b[0m│\u001b[0m 6.047643564356435 \u001b[0m│\u001b[0m\n",
      "└\u001b[0m─────────\u001b[0m┴\u001b[0m───────────────────\u001b[0m┘\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(measure = MLJBase.Measure[rms, mav],\n",
       " measurement = [8.668102471357711, 6.047643564356435],\n",
       " per_fold = Array{Float64,1}[[8.525465870955774, 8.52461967445231, 10.74455588603451, 9.393386761519249, 6.152484163826722], [6.489306930693069, 5.434059405940592, 7.613069306930692, 6.033663366336635, 4.668118811881189]],\n",
       " per_observation = Missing[missing, missing],)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = @load_boston\n",
    "model = @load KNNRegressor\n",
    "evaluate(model, X, y, resampling=CV(nfolds=5), measure=[rms, mav])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Basic fit/evaluate/predict by hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: A model type \"DecisionTreeClassifier\" is already loaded. \n",
      "│ No new code loaded. \n",
      "└ @ MLJModels /Users/anthony/Dropbox/Julia7/MLJ/MLJModels/src/loading.jl:41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using RDatasets\n",
    "vaso = dataset(\"robustbase\", \"vaso\"); # a DataFrame\n",
    "y, X = unpack(vaso, ==(:Y), c -> true; :Y => Multiclass)\n",
    "\n",
    "tree_model = @load DecisionTreeClassifier\n",
    "tree_model.max_depth=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bind the model and data together in a *machine* , which will\n",
    "additionally store the learned parameters (*fitresults*) when fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @ 1…17\u001b[39m\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = machine(tree_model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split row indices into training and evaluation rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = partition(eachindex(y), 0.7, shuffle=true, rng=1234); # 70:30 split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit on train and evaluate on test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{DecisionTreeClassifier} @ 1…17\u001b[39m.\n",
      "└ @ MLJ /Users/anthony/Dropbox/Julia7/MLJ/MLJ/src/machines.jl:141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.135369212298553"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(tree, rows=train)\n",
    "yhat = predict(tree, rows=test);\n",
    "mean(cross_entropy(yhat, y[test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{UnivariateFinite{Int64,UInt8,Float64},1}:\n",
       " UnivariateFinite(0=>0.2727272727272727, 1=>0.7272727272727273) \n",
       " UnivariateFinite(0=>0.02439024390243903, 1=>0.9756097560975611)\n",
       " UnivariateFinite(0=>0.02439024390243903, 1=>0.9756097560975611)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew = (Volume=3*rand(3), Rate=3*rand(3))\n",
    "predict(tree, Xnew)      # a vector of distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{CategoricalValue{Int64,UInt8},1}:\n",
       " 1\n",
       " 1\n",
       " 1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_mode(tree, Xnew) # a vector of point-predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  *More on machines (implementation detail)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, calling `fit!` on a machine calls either\n",
    "`MLJBase.fit` or `MLJBase.update` depending on the machine's\n",
    "internal state, as recorded in additional fields `previous_model`\n",
    "and `rows`. These lower level methods dispatch on the model and a\n",
    "view of the data depending on the optional `rows` keyword argument\n",
    "of `fit!` (all rows by default). In this way, if a model `update`\n",
    "method is implemented, calls to `fit!` can avoid redundant\n",
    "calculations for certain kinds of model mutations (eg, increasing\n",
    "the number of epochs in a neural network)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a complete list of the fields of a machine:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model` - the struct containing the hyperparameters to be used\n",
    "in calls to `fit!`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `fitresult` - the learned parameters in a raw form, initially undefined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `args` -  a tuple of the data (in the supervised learning example above, `args = (X, y)`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `report` - outputs of training not encoded in `fitresult` (eg, feature rankings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `previous_model` - a deep copy of the model used in the last call to `fit!`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `rows` -  a copy of the row indices used in last call to `fit!`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `cache`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More performance evaluation examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LossFunctions.ZeroOneLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model + data directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌\u001b[0m───────────────\u001b[0m┬\u001b[0m────────────────────\u001b[0m┐\u001b[0m\n",
      "│\u001b[0m\u001b[1m measure       \u001b[0m│\u001b[0m\u001b[1m measurement        \u001b[0m│\u001b[0m\n",
      "├\u001b[0m───────────────\u001b[0m┼\u001b[0m────────────────────\u001b[0m┤\u001b[0m\n",
      "│\u001b[0m cross_entropy \u001b[0m│\u001b[0m 1.135369212298553  \u001b[0m│\u001b[0m\n",
      "│\u001b[0m ZeroOneLoss   \u001b[0m│\u001b[0m 0.4166666666666667 \u001b[0m│\u001b[0m\n",
      "└\u001b[0m───────────────\u001b[0m┴\u001b[0m────────────────────\u001b[0m┘\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(measure = Any[cross_entropy, ZeroOneLoss()],\n",
       " measurement = [1.135369212298553, 0.4166666666666667],\n",
       " per_fold = Array{Float64,1}[[1.135369212298553], [0.4166666666666667]],\n",
       " per_observation = Array{Array{Float64,1},1}[[[0.10536051565782628, 3.7135720667043075, 0.10536051565782628, 2.3025850929940455, 0.10536051565782628, 0.3184537311185346, 0.02469261259037141, 0.3184537311185346, 0.3184537311185346, 1.2992829841302609, 3.7135720667043075, 1.2992829841302609]], [[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]]],)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(tree_model, X, y,\n",
    "         resampling=Holdout(fraction_train=0.7, shuffle=true, rng=1234),\n",
    "         measure=[cross_entropy, ZeroOneLoss()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a machine is already defined, as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌\u001b[0m───────────────\u001b[0m┬\u001b[0m────────────────────\u001b[0m┐\u001b[0m\n",
      "│\u001b[0m\u001b[1m measure       \u001b[0m│\u001b[0m\u001b[1m measurement        \u001b[0m│\u001b[0m\n",
      "├\u001b[0m───────────────\u001b[0m┼\u001b[0m────────────────────\u001b[0m┤\u001b[0m\n",
      "│\u001b[0m cross_entropy \u001b[0m│\u001b[0m 1.135369212298553  \u001b[0m│\u001b[0m\n",
      "│\u001b[0m ZeroOneLoss   \u001b[0m│\u001b[0m 0.4166666666666667 \u001b[0m│\u001b[0m\n",
      "└\u001b[0m───────────────\u001b[0m┴\u001b[0m────────────────────\u001b[0m┘\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(measure = Any[cross_entropy, ZeroOneLoss()],\n",
       " measurement = [1.135369212298553, 0.4166666666666667],\n",
       " per_fold = Array{Float64,1}[[1.135369212298553], [0.4166666666666667]],\n",
       " per_observation = Array{Array{Float64,1},1}[[[0.10536051565782628, 3.7135720667043075, 0.10536051565782628, 2.3025850929940455, 0.10536051565782628, 0.3184537311185346, 0.02469261259037141, 0.3184537311185346, 0.3184537311185346, 1.2992829841302609, 3.7135720667043075, 1.2992829841302609]], [[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]]],)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate!(tree,\n",
    "          resampling=Holdout(fraction_train=0.7, shuffle=true, rng=1234),\n",
    "          measure=[cross_entropy, ZeroOneLoss()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 5 folds: 100%[=========================] Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌\u001b[0m───────────────\u001b[0m┬\u001b[0m────────────────────\u001b[0m┐\u001b[0m\n",
      "│\u001b[0m\u001b[1m measure       \u001b[0m│\u001b[0m\u001b[1m measurement        \u001b[0m│\u001b[0m\n",
      "├\u001b[0m───────────────\u001b[0m┼\u001b[0m────────────────────\u001b[0m┤\u001b[0m\n",
      "│\u001b[0m cross_entropy \u001b[0m│\u001b[0m 0.8107153382628913 \u001b[0m│\u001b[0m\n",
      "│\u001b[0m ZeroOneLoss   \u001b[0m│\u001b[0m 0.4                \u001b[0m│\u001b[0m\n",
      "└\u001b[0m───────────────\u001b[0m┴\u001b[0m────────────────────\u001b[0m┘\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(measure = Any[cross_entropy, ZeroOneLoss()],\n",
       " measurement = [0.8107153382628913, 0.4],\n",
       " per_fold = Array{Float64,1}[[0.44130929246809064, 1.2635805032959784, 0.6459172309118898, 0.8778906002819279, 0.8248790643565697], [0.5714285714285714, 0.2857142857142857, 0.2857142857142857, 0.5714285714285714, 0.2857142857142857]],\n",
       " per_observation = Array{Array{Float64,1},1}[[[0.02469261259037141, 0.02469261259037141, 0.7537718023763802, 0.7537718023763802, 0.7537718023763802, 0.7537718023763802, 0.02469261259037141], [0.3483066942682157, 0.3483066942682157, 0.3483066942682157, 0.3483066942682157, 3.7135720667043075, 3.7135720667043075, 0.02469261259037141], [0.02469261259037141, 0.1823215567939546, 0.1823215567939546, 2.0149030205422647, 1.791759469228055, 0.1823215567939546, 0.1431008436406733], [1.3862943611198906, 1.3862943611198906, 1.3862943611198906, 0.2876820724517809, 0.02469261259037141, 0.2876820724517809, 1.3862943611198906], [0.02469261259037141, 0.02469261259037141, 0.02469261259037141, 3.7135720667043075, 0.8109302162163288, 0.587786664902119, 0.587786664902119]], [[0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0], [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]]],)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate!(tree, resampling=CV(nfolds=5, shuffle=true, rng=1234),\n",
    "          measure=[cross_entropy, ZeroOneLoss()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With user-specified train/evaluation pairs of row indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 3 folds: 100%[=========================] Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌\u001b[0m───────────────\u001b[0m┬\u001b[0m─────────────────────\u001b[0m┐\u001b[0m\n",
      "│\u001b[0m\u001b[1m measure       \u001b[0m│\u001b[0m\u001b[1m measurement         \u001b[0m│\u001b[0m\n",
      "├\u001b[0m───────────────\u001b[0m┼\u001b[0m─────────────────────\u001b[0m┤\u001b[0m\n",
      "│\u001b[0m cross_entropy \u001b[0m│\u001b[0m 0.895254695800462   \u001b[0m│\u001b[0m\n",
      "│\u001b[0m ZeroOneLoss   \u001b[0m│\u001b[0m 0.24136008918617616 \u001b[0m│\u001b[0m\n",
      "└\u001b[0m───────────────\u001b[0m┴\u001b[0m─────────────────────\u001b[0m┘\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(measure = Any[cross_entropy, ZeroOneLoss()],\n",
       " measurement = [0.895254695800462, 0.24136008918617616],\n",
       " per_fold = Array{Float64,1}[[0.7538091986662944, 1.1473950551467866, 0.7845598335883047], [0.30434782608695654, 0.30434782608695654, 0.11538461538461539]],\n",
       " per_observation = Array{Array{Float64,1},1}[[[0.15415067982725836, 0.15415067982725836, 0.15415067982725836, 0.15415067982725836, 0.15415067982725836, 1.9459101490553135, 0.15415067982725836, 0.02469261259037141, 1.9459101490553135, 1.9459101490553135  …  0.15415067982725836, 1.9459101490553135, 0.15415067982725836, 0.02469261259037141, 3.7135720667043075, 0.02469261259037141, 1.9459101490553135, 0.15415067982725836, 0.15415067982725836, 0.15415067982725836], [0.02469261259037141, 3.7135720667043075, 3.7135720667043075, 0.02469261259037141, 3.7135720667043075, 0.02469261259037141, 3.7135720667043075, 0.02469261259037141, 0.02469261259037141, 0.02469261259037141  …  0.02469261259037141, 0.02469261259037141, 0.02469261259037141, 0.02469261259037141, 3.7135720667043075, 0.02469261259037141, 0.02469261259037141, 0.02469261259037141, 0.02469261259037141, 0.02469261259037141], [0.02469261259037141, 0.02469261259037141, 0.02469261259037141, 0.6931471805599453, 0.6931471805599453, 0.6931471805599453, 0.6931471805599453, 0.6931471805599453, 0.6931471805599453, 0.02469261259037141  …  0.02469261259037141, 0.6931471805599453, 3.7135720667043075, 0.02469261259037141, 0.6931471805599453, 0.6931471805599453, 3.7135720667043075, 3.7135720667043075, 0.02469261259037141, 0.6931471805599453]], [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0  …  0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]]],)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1, f2, f3 = 1:13, 14:26, 27:36\n",
    "pairs = [(f1, vcat(f2, f3)), (f2, vcat(f3, f1)), (f3, vcat(f1, f2))];\n",
    "evaluate!(tree,\n",
    "          resampling=pairs,\n",
    "          measure=[cross_entropy, ZeroOneLoss()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing a hyperparameter and re-evaluating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 5 folds: 100%[=========================] Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌\u001b[0m───────────────\u001b[0m┬\u001b[0m─────────────────────\u001b[0m┐\u001b[0m\n",
      "│\u001b[0m\u001b[1m measure       \u001b[0m│\u001b[0m\u001b[1m measurement         \u001b[0m│\u001b[0m\n",
      "├\u001b[0m───────────────\u001b[0m┼\u001b[0m─────────────────────\u001b[0m┤\u001b[0m\n",
      "│\u001b[0m cross_entropy \u001b[0m│\u001b[0m 0.7857788118033404  \u001b[0m│\u001b[0m\n",
      "│\u001b[0m ZeroOneLoss   \u001b[0m│\u001b[0m 0.37142857142857133 \u001b[0m│\u001b[0m\n",
      "└\u001b[0m───────────────\u001b[0m┴\u001b[0m─────────────────────\u001b[0m┘\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(measure = Any[cross_entropy, ZeroOneLoss()],\n",
       " measurement = [0.7857788118033404, 0.37142857142857133],\n",
       " per_fold = Array{Float64,1}[[0.5192479199123463, 1.1617214839057737, 0.7334426224354447, 0.6982881261612496, 0.816193906601888], [0.42857142857142855, 0.2857142857142857, 0.2857142857142857, 0.5714285714285714, 0.2857142857142857]],\n",
       " per_observation = Array{Array{Float64,1},1}[[[0.02469261259037141, 0.02469261259037141, 0.02469261259037141, 1.1786549963416462, 1.1786549963416462, 1.1786549963416462, 0.02469261259037141], [0.6061358035703156, 0.02469261259037141, 0.02469261259037141, 0.02469261259037141, 3.7135720667043075, 3.7135720667043075, 0.02469261259037141], [0.02469261259037141, 0.02469261259037141, 0.02469261259037141, 3.7135720667043075, 1.0986122886681098, 0.02469261259037141, 0.2231435513142097], [0.9808292530117262, 0.9808292530117262, 0.9808292530117262, 0.4700036292457356, 0.02469261259037141, 0.4700036292457356, 0.9808292530117262], [0.02469261259037141, 0.02469261259037141, 0.02469261259037141, 3.7135720667043075, 1.252762968495368, 0.3364722366212129, 0.3364722366212129]], [[0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0], [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]]],)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model.max_depth = 3\n",
    "evaluate!(tree,\n",
    "          resampling=CV(nfolds=5, shuffle=true, rng=1234),\n",
    "          measure=[cross_entropy, ZeroOneLoss()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Inspecting training results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a ordinary least square model to some synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{LinearRegressor} @ 7…80\u001b[39m.\n",
      "└ @ MLJ /Users/anthony/Dropbox/Julia7/MLJ/MLJ/src/machines.jl:141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{LinearRegressor} @ 7…80\u001b[39m\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = rand(100)\n",
    "x2 = rand(100)\n",
    "\n",
    "X = (x1=x1, x2=x2)\n",
    "y = x1 - 2x2 + 0.1*rand(100);\n",
    "\n",
    "ols_model = @load LinearRegressor pkg=GLM\n",
    "ols =  machine(ols_model, X, y)\n",
    "fit!(ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a named tuple representing the learned parameters,\n",
    "human-readable if appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(coef = [0.9985128951528446, -1.9981845372437947],\n",
       " intercept = 0.05141139704717806,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get other training-related information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(deviance = 0.08067317714592058,\n",
       " dof_residual = 97.0,\n",
       " stderror = [0.009386992893038402, 0.00995817861943297, 0.0073417739672351065],\n",
       " vcov = [8.811563557395346e-5 -9.558303404671843e-6 -4.056936372724475e-5; -9.558303404671843e-6 9.916532141653193e-5 -4.6982822143496706e-5; -4.056936372724475e-5 -4.6982822143496706e-5 5.390164498597111e-5],)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report(ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Basic fit/transform for unsupervised models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([125, 100, 130, 9, 70, 148, 39, 64, 6, 107  …  134, 114, 52, 74, 44, 61, 83, 18, 122, 26], [97, 78, 30, 108, 101, 24, 85, 91, 135, 96  …  112, 144, 140, 72, 109, 41, 106, 147, 47, 5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = @load_iris\n",
    "train, test = partition(eachindex(y), 0.7, shuffle=true, rng=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate and fit the model/machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{PCA} @ 9…33\u001b[39m.\n",
      "└ @ MLJ /Users/anthony/Dropbox/Julia7/MLJ/MLJ/src/machines.jl:141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{PCA} @ 9…33\u001b[39m\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@load PCA\n",
    "pca_model = PCA(maxoutdim=2)\n",
    "pca = machine(pca_model, X)\n",
    "fit!(pca, rows=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform selected data bound to the machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform(pca, rows=test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(x1 = [4.819158264829177, 4.8208386973047, 5.111185670643473],\n",
       " x2 = [-4.4441147103696315, -4.4288641941901625, -4.71503950609489],)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew = (sepal_length=rand(3), sepal_width=rand(3),\n",
    "        petal_length=rand(3), petal_width=rand(3));\n",
    "transform(pca, Xnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Inverting learned transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{UnivariateStandardizer} @ 9…82\u001b[39m.\n",
      "└ @ MLJ /Users/anthony/Dropbox/Julia7/MLJ/MLJ/src/machines.jl:141\n"
     ]
    }
   ],
   "source": [
    "y = rand(100);\n",
    "stand_model = UnivariateStandardizer()\n",
    "stand = machine(stand_model, y)\n",
    "fit!(stand)\n",
    "z = transform(stand, y);\n",
    "@assert inverse_transform(stand, z) ≈ y # true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150×4 DataFrame\n",
       "│ Row │ sepal_length │ sepal_width │ petal_length │ petal_width │\n",
       "│     │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m     │\n",
       "├─────┼──────────────┼─────────────┼──────────────┼─────────────┤\n",
       "│ 1   │ 5.1          │ 3.5         │ 1.4          │ 0.2         │\n",
       "│ 2   │ 4.9          │ 3.0         │ 1.4          │ 0.2         │\n",
       "│ 3   │ 4.7          │ 3.2         │ 1.3          │ 0.2         │\n",
       "│ 4   │ 4.6          │ 3.1         │ 1.5          │ 0.2         │\n",
       "│ 5   │ 5.0          │ 3.6         │ 1.4          │ 0.2         │\n",
       "│ 6   │ 5.4          │ 3.9         │ 1.7          │ 0.4         │\n",
       "│ 7   │ 4.6          │ 3.4         │ 1.4          │ 0.3         │\n",
       "│ 8   │ 5.0          │ 3.4         │ 1.5          │ 0.2         │\n",
       "│ 9   │ 4.4          │ 2.9         │ 1.4          │ 0.2         │\n",
       "│ 10  │ 4.9          │ 3.1         │ 1.5          │ 0.1         │\n",
       "⋮\n",
       "│ 140 │ 6.9          │ 3.1         │ 5.4          │ 2.1         │\n",
       "│ 141 │ 6.7          │ 3.1         │ 5.6          │ 2.4         │\n",
       "│ 142 │ 6.9          │ 3.1         │ 5.1          │ 2.3         │\n",
       "│ 143 │ 5.8          │ 2.7         │ 5.1          │ 1.9         │\n",
       "│ 144 │ 6.8          │ 3.2         │ 5.9          │ 2.3         │\n",
       "│ 145 │ 6.7          │ 3.3         │ 5.7          │ 2.5         │\n",
       "│ 146 │ 6.7          │ 3.0         │ 5.2          │ 2.3         │\n",
       "│ 147 │ 6.3          │ 2.5         │ 5.0          │ 1.9         │\n",
       "│ 148 │ 6.5          │ 3.0         │ 5.2          │ 2.0         │\n",
       "│ 149 │ 6.2          │ 3.4         │ 5.4          │ 2.3         │\n",
       "│ 150 │ 5.9          │ 3.0         │ 5.1          │ 1.8         │, CategoricalString{UInt32}[\"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\"  …  \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\", \"virginica\"])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = @load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a model with nested hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: A model type \"DecisionTreeClassifier\" is already loaded. \n",
      "│ No new code loaded. \n",
      "└ @ MLJModels /Users/anthony/Dropbox/Julia7/MLJ/MLJModels/src/loading.jl:41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLJ.ProbabilisticEnsembleModel(atom = DecisionTreeClassifier(pruning_purity = 1.0,\n",
       "                                                             max_depth = -1,\n",
       "                                                             min_samples_leaf = 1,\n",
       "                                                             min_samples_split = 2,\n",
       "                                                             min_purity_increase = 0.0,\n",
       "                                                             n_subfeatures = 0,\n",
       "                                                             display_depth = 5,\n",
       "                                                             post_prune = false,\n",
       "                                                             merge_purity_threshold = 0.9,\n",
       "                                                             pdf_smoothing = 0.05,),\n",
       "                               weights = Float64[],\n",
       "                               bagging_fraction = 0.8,\n",
       "                               rng = MersenneTwister(UInt32[0x71271325, 0x5861ba72, 0x34abacc2, 0x27102d83]),\n",
       "                               n = 300,\n",
       "                               parallel = true,\n",
       "                               out_of_bag_measure = Any[],)\u001b[34m @ 8…22\u001b[39m"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model = @load DecisionTreeClassifier\n",
    "forest_model = EnsembleModel(atom=tree_model, n=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect all hyperparameters, even nested ones (returns nested named tuple):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(atom = (pruning_purity = 1.0,\n",
       "         max_depth = -1,\n",
       "         min_samples_leaf = 1,\n",
       "         min_samples_split = 2,\n",
       "         min_purity_increase = 0.0,\n",
       "         n_subfeatures = 0,\n",
       "         display_depth = 5,\n",
       "         post_prune = false,\n",
       "         merge_purity_threshold = 0.9,\n",
       "         pdf_smoothing = 0.05,),\n",
       " weights = Float64[],\n",
       " bagging_fraction = 0.8,\n",
       " rng = MersenneTwister(UInt32[0x71271325, 0x5861ba72, 0x34abacc2, 0x27102d83]),\n",
       " n = 300,\n",
       " parallel = true,\n",
       " out_of_bag_measure = Any[],)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params(forest_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define ranges for hyperparameters to be tuned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJ.NumericRange(field = :bagging_fraction,\n",
       "                 lower = 0.5,\n",
       "                 upper = 1.0,\n",
       "                 scale = :log10,)\u001b[34m @ 1…28\u001b[39m"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = range(forest_model, :bagging_fraction, lower=0.5, upper=1.0, scale=:log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJ.NumericRange(field = :(atom.n_subfeatures),\n",
       "                 lower = 1,\n",
       "                 upper = 4,\n",
       "                 scale = :linear,)\u001b[34m @ 1…75\u001b[39m"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = range(forest_model, :(atom.n_subfeatures), lower=1, upper=4) # nested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap the model in a tuning strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJ.ProbabilisticTunedModel(model = MLJ.ProbabilisticEnsembleModel(atom = \u001b[34mDecisionTreeClassifier @ 1…80\u001b[39m,\n",
       "                                                                   weights = Float64[],\n",
       "                                                                   bagging_fraction = 0.8,\n",
       "                                                                   rng = MersenneTwister(UInt32[0x71271325, 0x5861ba72, 0x34abacc2, 0x27102d83]),\n",
       "                                                                   n = 300,\n",
       "                                                                   parallel = true,\n",
       "                                                                   out_of_bag_measure = Any[],),\n",
       "                            tuning = Grid(resolution = 12,\n",
       "                                          parallel = true,),\n",
       "                            resampling = CV(nfolds = 6,\n",
       "                                            shuffle = false,\n",
       "                                            rng = MersenneTwister(UInt32[0x71271325, 0x5861ba72, 0x34abacc2, 0x27102d83]),),\n",
       "                            measure = MLJBase.CrossEntropy(),\n",
       "                            weights = nothing,\n",
       "                            operation = StatsBase.predict,\n",
       "                            ranges = MLJ.NumericRange{T,Symbol} where T[\u001b[34mNumericRange @ 1…28\u001b[39m, \u001b[34mNumericRange @ 1…75\u001b[39m],\n",
       "                            full_report = true,\n",
       "                            train_best = true,)\u001b[34m @ 1…49\u001b[39m"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_forest = TunedModel(model=forest_model,\n",
    "                          tuning=Grid(resolution=12),\n",
    "                          resampling=CV(nfolds=6),\n",
    "                          ranges=[r1, r2],\n",
    "                          measure=cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bound the wrapped model to data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ProbabilisticTunedModel} @ 1…60\u001b[39m\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned = machine(tuned_forest, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the resultant machine optimizes the hyperaparameters specified in\n",
    "`range`, using the specified resampling strategy and performance\n",
    "measure, and retrains on all data bound to the machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{ProbabilisticTunedModel} @ 1…60\u001b[39m.\n",
      "└ @ MLJ /Users/anthony/Dropbox/Julia7/MLJ/MLJ/src/machines.jl:141\n",
      "┌ Info: Mimimizing cross_entropy. \n",
      "└ @ MLJ /Users/anthony/Dropbox/Julia7/MLJ/MLJ/src/tuning.jl:160\n",
      "\u001b[33mIterating over a 48-point grid: 100%[=========================] Time: 0:00:40\u001b[39m\n",
      "┌ Info: Training best model on all supplied data.\n",
      "└ @ MLJ /Users/anthony/Dropbox/Julia7/MLJ/MLJ/src/tuning.jl:252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ProbabilisticTunedModel} @ 1…60\u001b[39m\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the optimal model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(best_model = \u001b[34mProbabilisticEnsembleModel{DecisionTreeClassifier} @ 1…63\u001b[39m,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = fitted_params(tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJ.ProbabilisticEnsembleModel(atom = DecisionTreeClassifier(pruning_purity = 1.0,\n",
       "                                                             max_depth = -1,\n",
       "                                                             min_samples_leaf = 1,\n",
       "                                                             min_samples_split = 2,\n",
       "                                                             min_purity_increase = 0.0,\n",
       "                                                             n_subfeatures = 3,\n",
       "                                                             display_depth = 5,\n",
       "                                                             post_prune = false,\n",
       "                                                             merge_purity_threshold = 0.9,\n",
       "                                                             pdf_smoothing = 0.05,),\n",
       "                               weights = Float64[],\n",
       "                               bagging_fraction = 0.5,\n",
       "                               rng = MersenneTwister(UInt32[0x71271325, 0x5861ba72, 0x34abacc2, 0x27102d83]),\n",
       "                               n = 300,\n",
       "                               parallel = true,\n",
       "                               out_of_bag_measure = Any[],)\u001b[34m @ 1…63\u001b[39m"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting details of tuning procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(parameter_names = [\"bagging_fraction\" \"atom.n_subfeatures\"],\n",
       " parameter_scales = Symbol[:log10 :linear],\n",
       " parameter_values = Any[0.5 1; 0.5325205447199813 1; … ; 0.9389309106617063 4; 1.0 4],\n",
       " measurements = [0.23836844761285972, 0.24310768116519496, 0.23155959227133427, 0.2358303191590729, 0.23388918367157183, 0.23944002555125055, 0.22931761600908399, 0.22924432030705047, 0.22621287086704908, 0.23123283225576788  …  0.1830737398891659, 0.19017188641338933, 0.2062563314942637, 0.2041996514962502, 0.210012168891926, 0.21305031478959782, 0.22735490003858747, 0.2359797272653158, 0.2584476524785048, 0.32572198859316304],\n",
       " best_measurement = 0.17477371176810844,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report(tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot result of a 2D parameter tune, use `using Plots; pyplot();\n",
    "plot(tuned)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on new data using the optimized model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{UnivariateFinite{String,UInt32,Float64},1}:\n",
       " UnivariateFinite(setosa=>0.9677419354838652, versicolor=>0.01612903225806445, virginica=>0.01612903225806445)\n",
       " UnivariateFinite(setosa=>0.9677419354838652, versicolor=>0.01612903225806445, virginica=>0.01612903225806445)\n",
       " UnivariateFinite(setosa=>0.9677419354838652, versicolor=>0.01612903225806445, virginica=>0.01612903225806445)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(tuned, Xnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
